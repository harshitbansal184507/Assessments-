{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitbansal184507/Assessments-/blob/main/FittLyf/FittLyf_Data_Science_Intern_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfcLRY8F-IRW"
      },
      "source": [
        "## Checklist\n",
        "*Fill this table appropriately as you progress in your tasks:*\n",
        "\n",
        "\n",
        "|**Section**|**Completion**|\n",
        "|-|-|\n",
        "|**Section 1**| **Completed** |\n",
        "|  Q 1 | Completed |\n",
        "|  Q 2 | Completed |\n",
        "|  Q 3 | Completed |\n",
        "|  Q 4 | Completed |\n",
        "|  Q 5 | Completed |\n",
        "|**Section 2**| **Completed** |\n",
        "|  Q 1 | Completed |\n",
        "|  Q 2 | Completed |\n",
        "|  Q 3 | Completed |\n",
        "|  Q 4 | Completed |\n",
        "|  Q 5 | Completed |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color='red'>**PLEASE READ THIS CAREFULLY**</font><br>\n",
        "In this assignment you will be asked to solve the problems presented to you, and then create a PDF or maybe a powerpoint presentation, or maybe even a text file with your thoughts on a certain topic. And definitely a .ipynb file or some .py files.<br><br>\n",
        "All of these files should be <font color='cyan'>***uploaded into a folder in Google Drive***</font> and made <font color='cyan'>***publicly accessible***</font> so that we can view your work without any form of back and forth requesting access.<br>\n",
        "<font color='brown'>***Reminder***</font> : You need to make each file you upload publicly accessible, not just the folder. After uploading do check that all files are accessible and openable as intended."
      ],
      "metadata": {
        "id": "KLV5mJB4-p6V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0fSa5a8zBiq"
      },
      "source": [
        "---\n",
        "# Introduction\n",
        "\n",
        "Welcome! As a budding Data Scientist, you've been entrusted with the exciting opportunity to dive into the realms of Data Science and unravel valuable insights that will steer our organization towards success. Your efforts have the power to shape decision-making processes and position you as a key player in our team.\n",
        "\n",
        "We're committed to providing everyone with an equal chance to showcase their talents. This guided assignment is designed not only to evaluate your fit within our dynamic team but also to help you grasp the type of impactful work you'll be contributing to as an intern.  We're confident that, with your hard work, you'll not only meet but exceed expectations. Let's get started! &#x1F4AA;\n",
        "\n",
        "This is a practical exercise that will test your analytical & programming skills as well as your understanding of various components of the analytics life cycle. **You would be required to share an iPython notebook (`.ipynb` format) and a Presentation document (`.pptx` format) uploaded to a folder in Google drive and shared as a \"Google Drive link\" which has viewer access to everyone.**\n",
        "\n",
        "**Note:** You will not be able to edit this file directly, so make a copy of it on your local machine or in Google Colab beforing answering different sections of this assessment.\n",
        "\n",
        "The final notebook shouldn't have the questions, it should only have appropriate headings for each section/sub-section and the questions should be correctly numbered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aRzAvIs-IRb"
      },
      "source": [
        "---\n",
        "# Instructions\n",
        "Please read carefully:\n",
        "- **Submit 1 Google drive link with all the answers. The submitted Google Colab notebook/PPT's name should be in `<your_full_name>_<date_of_submission>` format.**\n",
        "- **Your code, comments & output should be present in the colab notebook. Please make sure that all the output code and text are organized and readable in the submitted Google Colab notebook.**\n",
        "- You may not consult with any other person regarding the test. You are allowed to use internet searches, AI chatbots, books, or notes you have on hand.\n",
        "- **The test has 2 sections, both of which are mandatory.** Read the questions carefully and answer accordingly. **Code should be commented properly.**\n",
        "\n",
        "- In case of doubts please make thoughtful assumptions.\n",
        "\n",
        "**Start your Google Colab notebook with a checklist mentioning the parts you were/were not able to complete.** The table to fill is given at the top. Ideally, all sections must be marked \"Completed\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwFA-1M_-IRb"
      },
      "source": [
        "---\n",
        "<h1> About Data</h1>\n",
        "\n",
        "Analysing data and getting actionable insights is one of the very basic but key tasks of any data professional. For the purpose of this assessment, you have been provided with the data. The data for this section can be accessed from [Assignment Data Excel Sheet](https://docs.google.com/spreadsheets/d/1T9eggrYyjM9g7KrSwNMchw9NEJUbOgJV/edit?usp=sharing&ouid=107859560415035863900&rtpof=true&sd=true) (click on the hyperlink and download the dataset).\n",
        "\n",
        "The Microsoft excel file shared with you has 3 sheets:\n",
        "1. `WorkerFunnel` sheet\n",
        "2. `creditcard` sheet\n",
        "3. `creditcard_test` sheet\n",
        "\n",
        "**NOTE:** Download the `AssignmentData.xlsx` to your current directory accordingly. Don't make any changes to the data using excel, all data manipulations must be done within this notebook only and your codes must run on the original data file provided to you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auvfQL4PzBOn"
      },
      "source": [
        "# Section 1 - Funnel Analysis\n",
        "`WorkerFunnel` sheet has the details of a garment manufacturing process and the productivity of the employees at the organisation. This data allows you to understand the productivity of the workers over a span of 70 days. The different columns represent the following:\n",
        "\n",
        "| Column Name| Description|\n",
        "|-|-|\n",
        "| Date| Date in MM-DD-YYYY|\n",
        "| Quarter| A portion of the month. A month was divided into four or five quarters|\n",
        "| Department| Associated department with the instance|\n",
        "| Targeted Productivity| Targeted productivity set for each team for each day|\n",
        "| Overtime| Represents the amount of overtime by each team in minutes|\n",
        "| No. of Workers| Number of workers in each team|\n",
        "| Actual Productivity| The actual % of productivity that was delivered by the workers. It ranges from 0-1|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8Rc62xSnil6"
      },
      "source": [
        "Import data from the `WorkerFunnel` sheet of the `AssignmentData.xlsx` file into a dataframe named `funnel` and perform exploratory analysis.\n",
        "\n",
        "\n",
        "1. Identify and appropriately handle the missing/blank and duplicate values in the dataset, and explain the logic behind your strategy in a short paragraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0w8AHC4-IRf"
      },
      "source": [
        "2. Principal Component Analysis (PCA)<br>\n",
        "For reference, read about Dimensionality Reduction with PCA from [A guide to Principal Component Analysis (PCA)](https://www.shiksha.com/online-courses/articles/a-guide-to-principal-component-analysis-pca/), or this [GeeksforGeeks article](https://www.geeksforgeeks.org/principal-component-analysis-pca/). <br><br>\n",
        "\n",
        "  (i) Perform PCA on the following standardized features: `Targeted Productivity`, `Overtime`, `No. of Workers`, and `Actual Productivity`.<br><br>\n",
        "(ii) Determine the number of principal components that explain at least 90% of the variance in the data.<br><br>\n",
        "(iii) Visualize the explained variance by each principal component.<br><br>\n",
        "(iv) Provide an interpretation of the PCA results. How can these principal components be used to understand the productivity dynamics in the organization?\n",
        "<br><br>\n",
        "Expectation: You need to explain what insights you gained from the analysis. Write it after your work on this question, or provide a text file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiMWKGDdy4fh"
      },
      "source": [
        "3. Predictive Modeling and Time Series Analysis<br>\n",
        "For reference, read about Time Series Forecasting with ARIMA from [Understanding Time Series Forecasting with ARIMA](https://medium.com/@mubarakdaha/understanding-time-series-forecasting-with-arima-59cd7140d6c3).<br><br>\n",
        "(i) Build an ARIMA model to forecast the Actual Productivity for the next four quarters (four weeks).<br><br>\n",
        "(ii) Evaluate the model using Mean Absolute Percentage Error (MAPE) and Mean Squared Error (MSE).<br><br>\n",
        "(iii) Visualize the forecasted vs actual productivity values, and interpret the model’s accuracy.\n",
        "<br><br>\n",
        "Expectation: You are expected to create a clear and understandable chart that clearly shows the predicted productivity across the coming 4 quarters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Clustering Analysis<br><br>\n",
        "(i) Perform K-Means clustering on the Actual Productivity, Overtime, and No. of Workers.<br><br>\n",
        "(ii) Determine the optimal number of clusters using the Elbow method.<br><br>\n",
        "(iii) Visualize and interpret the clusters, focusing on how different segments of workers contribute to overall productivity.\n",
        "<br><br>\n",
        "Expectation: You are expected to create a visualisation that clearly explains the different segments' contribution. Add your interpretation as well."
      ],
      "metadata": {
        "id": "QFYJkBTCyQhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Budget Allocation Strategy (Bonus)<br><br>\n",
        "(i) The organization currently spends Rs. 8.4 lakh per quarter. Analyze the value brought by each department using Department Value = Actual Productivity / Department Quarterly Spend.<br><br>\n",
        "(ii) Suggest a revised budget allocation strategy to maximize productivity, and justify your recommendation.<br><br>\n",
        "(iii) Create a short PowerPoint presentation (3-4 slides) summarizing your analysis, the PCA findings, the forecasted productivity, and your budget allocation strategy."
      ],
      "metadata": {
        "id": "oAULrZh1ymuy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wizxTMvZEVKK"
      },
      "source": [
        "---\n",
        "# Section 2 - Anomaly detection\n",
        "\n",
        "You are tasked with detecting fraudulent transactions from a large dataset of credit card transactions. The data contains both normal and fraudulent transactions, and your goal is to identify the anomalies (frauds) using an unsupervised learning approach.\n",
        "\n",
        "Anomaly detection references\n",
        " - [Anomaly Detection in Machine Learning](https://www.shiksha.com/online-courses/articles/anomaly-detection/) - Shiksha Article\n",
        " - [Anomaly detection](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00320-x) - Springer Research paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNXcusp-DJZ"
      },
      "source": [
        "Import the `creditcard` sheet from the provided dataset. This dataset contains transactions made by credit cards in September 2013 by European cardholders. It presents transactions that occurred over two days, with 492 frauds out of 2,84,807 transactions.\n",
        "\n",
        "1. Data Import and Exploration\n",
        "- Import the creditcard.csv file into a dataframe named transactions.\n",
        "- Perform exploratory data analysis (EDA) to understand the distribution of the data, focusing on the Class column, which indicates whether a transaction is fraudulent (1) or not (0).\n",
        "- Visualize the distribution of transaction amounts for both fraudulent and non-fraudulent transactions.\n",
        "<br><br>\n",
        "Expectation: You are expected to present your interpretation of the dataset. Use visualisations to aid yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3iif-lndQ5F"
      },
      "source": [
        "2. Feature Engineering\n",
        "- The dataset includes 28 anonymized features (V1 to V28), along with Time and Amount.\n",
        "- Perform feature scaling on the Amount and Time features. Justify your choice of scaling method (e.g., Min-Max scaling, Standardization).\n",
        "- Consider dimensionality reduction (e.g., PCA) to visualize the data in two dimensions. Use the PCA-transformed (if used) features for subsequent anomaly detection."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Anomaly Detection Model\n",
        "\n",
        "- Implement an anomaly detection model using any two of the following methods:\n",
        " - Isolation Forest\n",
        " - Local Outlier Factor (LOF)\n",
        " - Autoencoders (for deep learning)\n",
        "- Train the model on the entire dataset, treating the majority class (`Class = 0`) as normal transactions and the minority class (`Class = 1`) as anomalies.\n",
        "- Evaluate the model’s performance using Precision, Recall, F1-Score, and ROC-AUC. Discuss the trade-offs in detecting frauds (e.g., false positives vs. false negatives).\n",
        "<br><br>\n",
        "Expectation: The evaluation metrics should be presented clearly. Present your views on the model, and what it means."
      ],
      "metadata": {
        "id": "PIxrAohgEKdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Visualizing Anomalies\n",
        "\n",
        "  Create a scatter plot of the two most significant features (after PCA or from the original features) with points colored based on whether they were classified as normal or fraudulent."
      ],
      "metadata": {
        "id": "XATI9-1REuL-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROYBTMGoVq0o"
      },
      "source": [
        "5. Write a function that accepts a new dataset of credit card transactions and the trained anomaly detection model, returning a list of transactions classified as fraudulent.\n",
        "\n",
        "  Develop a simple Streamlit app (you can follow this [tutorial](https://youtu.be/sogNluduBQQ?si=wA5a2wVh4bqeAtmi)) that allows users to upload a new set of credit card transactions, runs the anomaly detection model, and displays the results, including the visualizations of detected anomalies. For this, use the `creditcard_test` sheet provided in the data file. Finally, host this app on Streamlit Community Cloud using this [tutorial](https://blog.streamlit.io/host-your-streamlit-app-for-free/).\n",
        "  <br><br> Provide the link to the site as a text cell or comment<br>  \n",
        "    **Note**: You get bonus points for a neater and more presentable app.\n"
      ]
    }
  ]
}